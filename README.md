<p align="center">
	<img src="gtu.png" alt="GTU Logo" width="500" />
</p>

An advanced AI-powered system for analyzing Gujarat Technological University (GTU) Previous Year Questions (PYQs) to help students optimize their exam preparation strategy.

Live demo: https://gtu-pyqs-analyzer-cr7kag2ajmczjypucokxly.streamlit.app/

## About this project

GTU PYQs Analyzer is a compact Streamlit app that processes Gujarat Technological University previous-year question PDFs, extracts and analyzes questions, and produces AI-powered study recommendations and a downloadable analysis PDF.

## Technologies used

- Python 3.8+
- Streamlit (UI)
- PyMuPDF (fitz) for PDF text extraction
- NLTK for tokenization/stopwords
- scikit-learn for clustering and vectorization
- pandas, numpy for data handling
- reportlab for PDF generation
- plotly / matplotlib / seaborn for visualizations (Which is not on app, but in code)
- wordcloud, textstat, networkx for auxiliary analysis
- requests for API calls

## Deployed website

https://gtu-pyqs-analyzer-cr7kag2ajmczjypucokxly.streamlit.app/

## Code pipeline (high level)

1. User uploads one or more PDF files via the Streamlit UI (`main.py`).
2. `src/pdf_processor.py` extracts raw text and metadata from PDFs (PyMuPDF).
3. `src/question_processor.py` segments the raw text into individual questions and normalizes them.
4. `src/nlp_analyzer.py` runs NLP steps: keyword extraction, optional semantic clustering, frequency counts, and complexity/readability scoring.
5. `src/llm_analyzer.py` sends structured prompts + context to OpenRouter (LLM) and receives a `comprehensive_analysis` text and a personalized `study_plan`.
6. `src/visualizer.py` creates charts and visuals for the UI; `src/utils.py` contains helpers including `create_pdf_from_text()` which converts the analysis into a styled PDF.
7. Results are cached in `AnalysisCache` (session state) to speed repeated runs; users can download the analysis PDF from the results page.

## How the website works (user & backend flow)

User flow:
- Open the deployed site and enter your OpenRouter API key (or set via Streamlit secrets).
- Upload PDF question papers for a single subject.
- Click "Start Advanced Analysis" to run the pipeline.
- View the analysis across section tabs (frequency, topics, question types, difficulty, recommendations).
- Download the full analysis as a PDF.

Backend flow:
- The app processes uploaded PDFs one-by-one, extracts text, and segments questions.
- Basic NLP (keywords, frequency, clustering) runs locally to produce summaries and context.
- A final comprehensive analysis and a personalized study plan are generated by an LLM via OpenRouter using the extracted questions and NLP context.
- The final text is parsed and displayed in tabbed sections; the PDF generator formats headings, lists, and inline bold/italic to preserve readability.

## About OpenRouter

OpenRouter is a gateway/marketplace that provides access to LLM models (e.g., GPT-family and others) via a single API endpoint. This app uses OpenRouter as the LLM backend to generate the `comprehensive_analysis` and the `study_plan`.

Notes about using OpenRouter with this app:
- You must supply an `OPENROUTER_API_KEY` (stored in Streamlit secrets or as an environment variable).
- API usage may incur costs and rate limits; keep credentials private and monitor usage in your OpenRouter dashboard.
- The app sends only the minimal necessary context (extracted questions and NLP summaries) to the LLM to keep prompts focused and reduce token usage.

---

If you want this README expanded with screenshots or a short architecture diagram, tell me where to add them and I will update the file.

## Key Features (as deployed)
- Upload multiple PDF question papers (same subject recommended)
- Automatic question extraction and basic preprocessing
- NLP analysis: key topics/keywords, optional semantic clustering, frequency and complexity summaries
- AI analysis via OpenRouter: comprehensive analysis text and a personalized study plan
- Download full analysis as a styled PDF (Markdown-like headings, bold/italic, bullets)
- Session caching to speed up repeated analysis runs

## Quick Start (local)
1. Clone the repo
```bash
git clone https://github.com/yourusername/gtu-pyqs-analyzer.git
cd gtu-pyqs-analyzer
```
2. Install dependencies
```bash
pip install -r requirements.txt
```
3. (Optional) Add your OpenRouter API key locally for testing:
Create `.streamlit/secrets.toml` (local only, do not commit):
```toml
OPENROUTER_API_KEY = "your_openrouter_api_key_here"
```
4. Run the app
```bash
streamlit run main.py
```
Open http://localhost:8501 in your browser.

## Deploy (Streamlit Community Cloud)
1. Push this repository to GitHub.
2. Go to https://streamlit.io/cloud and create a new app pointing to this repo and branch.
3. In the app settings, add `OPENROUTER_API_KEY` in Secrets.

The app reads the API key from `st.secrets` or the `OPENROUTER_API_KEY` environment variable.

## Removed / Not included in the deployed app
- No public JSON/TXT download buttons are exposed on the site (PDF export only)
- No multi-LLM UI (app uses OpenRouter as the LLM back-end)
- Advanced deployment/CI examples were removed from this README — contact the maintainer if you need a Docker/GitHub Actions setup.

## Project layout
- `main.py` — Streamlit application entry
- `config/` — configuration constants
- `src/` — core modules: PDF extraction, question processing, NLP, LLM integration, utilities
- `assets/` — static assets (styles, logo)

## Need a change?
If the live app is missing something you rely on, tell me which features or downloads you want visible and I will update the app and README to match.

---
- **Caching**: Store results for faster repeat analysis

